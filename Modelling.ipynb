{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d98997ee-17d4-44af-9c5d-fba640872107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Đang xử lý dữ liệu ---\n",
      "Top 20 Tags: ['ai', 'javascript', 'development', 'aws', 'devops', 'reconnection', 'react', 'java', 'go', 'kubernetes', 'nodejs', 'cometapi', 'docker', 'android', 'database', 'python', 'security', 'blockchain', 'php', 'typescript']\n",
      "\n",
      "--- 2. Xây dựng Ma trận tương đồng (Soft Metric) ---\n",
      "\n",
      "Ví dụ: Top 3 tag giống 'ai' nhất:\n",
      "[('reconnection', 0.6486177210112248), ('development', 0.5854952003921959), ('python', 0.532715829245051)]\n",
      "\n",
      "--- 3. Training XGBoost ---\n",
      "\n",
      "--- 4. Kết quả ---\n",
      "Hard Accuracy Train: 1.0000\n",
      "Hard Accuracy Test: 0.5008\n",
      "Soft Precision Train (threshold=0.7): 1.0000\n",
      "Soft Precision Test (threshold=0.7): 0.6206\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"--- 1. Đang xử lý dữ liệu ---\")\n",
    "df = pd.read_csv('data_train.csv')\n",
    "df['tags_list'] = df['tags_list'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "all_tags_flat = [tag for sublist in df['tags_list'] for tag in sublist]\n",
    "top_20_tags = [tag for tag, count in Counter(all_tags_flat).most_common(20)]\n",
    "top_20_set = set(top_20_tags)\n",
    "print(f\"Top 20 Tags: {top_20_tags}\")\n",
    "\n",
    "print(\"\\n--- 2. Xây dựng Ma trận tương đồng (Soft Metric) ---\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['text_content'])\n",
    "\n",
    "def get_tag_centroids(df, X_tfidf, all_unique_tags):\n",
    "    tag_centroids = {}\n",
    "    for tag in all_unique_tags:\n",
    "        indices = df[df['tags_list'].apply(lambda tags: tag in tags)].index\n",
    "        if len(indices) > 0:\n",
    "            centroid = np.mean(X_tfidf[indices], axis=0)\n",
    "            tag_centroids[tag] = np.asarray(centroid).flatten()\n",
    "    return tag_centroids\n",
    "\n",
    "all_unique_tags = list(set(all_tags_flat))\n",
    "tag_centroids = get_tag_centroids(df, X_tfidf, all_unique_tags)\n",
    "\n",
    "def calculate_tag_similarity(tag_centroids, top_20, all_tags):\n",
    "    similarity_map = {}\n",
    "    valid_tags = [t for t in all_tags if t in tag_centroids]\n",
    "    valid_top_20 = [t for t in top_20 if t in tag_centroids]\n",
    "    if not valid_tags or not valid_top_20: return {}\n",
    "    vectors_all = np.array([tag_centroids[t] for t in valid_tags])\n",
    "    vectors_top20 = np.array([tag_centroids[t] for t in valid_top_20])\n",
    "    sim_matrix = cosine_similarity(vectors_all, vectors_top20)\n",
    "    for i, tag_rare in enumerate(valid_tags):\n",
    "        similarity_map[tag_rare] = {}\n",
    "        for j, tag_top in enumerate(valid_top_20):\n",
    "            similarity_map[tag_rare][tag_top] = sim_matrix[i][j]\n",
    "    return similarity_map\n",
    "\n",
    "sim_map = calculate_tag_similarity(tag_centroids, top_20_tags, all_unique_tags)\n",
    "\n",
    "if 'ai' in top_20_tags:\n",
    "    print(\"\\nVí dụ: Top 3 tag giống 'ai' nhất:\")\n",
    "    ai_sims = []\n",
    "    for t in all_unique_tags:\n",
    "        if t in sim_map and 'ai' in sim_map[t]:\n",
    "            if t != 'ai':\n",
    "                ai_sims.append((t, sim_map[t]['ai']))\n",
    "    print(sorted(ai_sims, key=lambda x: x[1], reverse=True)[:3])\n",
    "\n",
    "df['filtered_tags'] = df['tags_list'].apply(lambda tags: [t for t in tags if t in top_20_set])\n",
    "df_train_clean = df[df['filtered_tags'].map(len) > 0].reset_index(drop=True)\n",
    "\n",
    "X = df_train_clean['text_content']\n",
    "y = df_train_clean['filtered_tags']\n",
    "\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X, y, df_train_clean.index, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "y_test_original_tags = df.iloc[df_train_clean.iloc[idx_test].index]['tags_list'].values\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "svd = TruncatedSVD(n_components=200)\n",
    "X_train_vec = svd.fit_transform(tfidf.fit_transform(X_train))\n",
    "X_test_vec = svd.transform(tfidf.transform(X_test))\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=top_20_tags)\n",
    "y_train_bin = mlb.fit_transform(y_train)\n",
    "y_test_bin = mlb.transform(y_test)\n",
    "\n",
    "print(\"\\n--- 3. Training XGBoost ---\")\n",
    "clf = OneVsRestClassifier(XGBClassifier(n_estimators=100, tree_method='hist', n_jobs=-1))\n",
    "clf.fit(X_train_vec, y_train_bin)\n",
    "\n",
    "y_train_pred_bin = clf.predict(X_train_vec)\n",
    "y_pred_bin = clf.predict(X_test_vec)\n",
    "y_train_pred_tags = mlb.inverse_transform(y_train_pred_bin)\n",
    "y_pred_tags = mlb.inverse_transform(y_pred_bin)\n",
    "\n",
    "print(\"\\n--- 4. Kết quả ---\")\n",
    "def calculate_soft_score(pred_tags_list, original_tags_list, sim_map, threshold=0.7):\n",
    "    soft_precisions = []\n",
    "    for preds, originals in zip(pred_tags_list, original_tags_list):\n",
    "        if len(preds) == 0:\n",
    "            soft_precisions.append(0)\n",
    "            continue\n",
    "        hits = 0\n",
    "        for p_tag in preds:\n",
    "            is_match = False\n",
    "            if p_tag in originals:\n",
    "                is_match = True\n",
    "            else:\n",
    "                for o_tag in originals:\n",
    "                    if o_tag in sim_map and p_tag in sim_map[o_tag]:\n",
    "                        if sim_map[o_tag][p_tag] >= threshold:\n",
    "                            is_match = True\n",
    "                            break\n",
    "            if is_match: hits += 1\n",
    "        soft_precisions.append(hits / len(preds))\n",
    "    return np.mean(soft_precisions)\n",
    "\n",
    "y_test_top20 = y_test.values\n",
    "hard_correct_train = sum([set(p) == set(t) for p, t in zip(y_train_pred_tags, y_train.values)])\n",
    "hard_correct_test = sum([set(p) == set(t) for p, t in zip(y_pred_tags, y_test_top20)])\n",
    "print(f\"Hard Accuracy Train: {hard_correct_train/len(y_train):.4f}\")\n",
    "print(f\"Hard Accuracy Test: {hard_correct_test/len(y_test):.4f}\")\n",
    "\n",
    "soft_score_train = calculate_soft_score(y_train_pred_tags, y_train.values, sim_map, threshold=0.7)\n",
    "soft_score_test = calculate_soft_score(y_pred_tags, y_test_original_tags, sim_map, threshold=0.7)\n",
    "print(f\"Soft Precision Train (threshold=0.7): {soft_score_train:.4f}\")\n",
    "print(f\"Soft Precision Test (threshold=0.7): {soft_score_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4d15b88-cf76-49e2-b280-aee777af626f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Đang xử lý dữ liệu ---\n",
      "\n",
      "--- 2. Tạo không gian Vector ngữ nghĩa ---\n",
      "Không gian vector: (2619, 200)\n",
      "\n",
      "--- 3. Tính toán vị trí trung tâm (Centroids) của từng Tag ---\n",
      "Đã học được vị trí của 20 tags.\n",
      "\n",
      "--- 4. Phân cụm các Tags (Tạo nhóm ngữ nghĩa) ---\n",
      "\n",
      "--- 5. Dự đoán trên tập Test ---\n",
      "\n",
      "--- KẾT QUẢ ĐÁNH GIÁ ---\n",
      "Tổng số bài test: 655\n",
      "Cluster-based Soft Accuracy: 0.8595\n",
      "(Nghĩa là: 85.95% số bài viết được gán nhãn ĐÚNG CHỦ ĐỀ/NHÓM NGỮ NGHĨA)\n",
      "\n",
      "--- Ví dụ thực tế ---\n",
      "Bài 0:\n",
      "  - Tag thật: ['development', 'javascript'] (Cụm ID: [1, 1])\n",
      "  - Dự đoán:  ['java', 'development', 'reconnection'] (Top 1 Cụm ID: 1)\n",
      "  => Kết quả: ĐÚNG CỤM\n",
      "------------------------------\n",
      "Bài 1:\n",
      "  - Tag thật: ['ai'] (Cụm ID: [1])\n",
      "  - Dự đoán:  ['ai', 'reconnection', 'development'] (Top 1 Cụm ID: 1)\n",
      "  => Kết quả: ĐÚNG CỤM\n",
      "------------------------------\n",
      "Bài 2:\n",
      "  - Tag thật: ['security'] (Cụm ID: [1])\n",
      "  - Dự đoán:  ['security', 'nodejs', 'javascript'] (Top 1 Cụm ID: 1)\n",
      "  => Kết quả: ĐÚNG CỤM\n",
      "------------------------------\n",
      "Bài 3:\n",
      "  - Tag thật: ['aws'] (Cụm ID: [6])\n",
      "  - Dự đoán:  ['typescript', 'aws', 'reconnection'] (Top 1 Cụm ID: 7)\n",
      "  => Kết quả: SAI\n",
      "------------------------------\n",
      "Bài 4:\n",
      "  - Tag thật: ['javascript', 'nodejs', 'typescript'] (Cụm ID: [1, 1, 7])\n",
      "  - Dự đoán:  ['nodejs', 'javascript', 'security'] (Top 1 Cụm ID: 1)\n",
      "  => Kết quả: ĐÚNG CỤM\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# =============================================================================\n",
    "# 1. LOAD DỮ LIỆU\n",
    "# =============================================================================\n",
    "print(\"--- 1. Đang xử lý dữ liệu ---\")\n",
    "df = pd.read_csv('data_train.csv')\n",
    "# Parse chuỗi list thành list thật\n",
    "df['tags_list'] = df['tags_list'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "# Bỏ dòng rỗng\n",
    "df = df[df['tags_list'].map(len) > 0].reset_index(drop=True)\n",
    "\n",
    "# Chia tập Train/Test\n",
    "# Lưu ý: Ta dùng toàn bộ tag, KHÔNG lọc Top 20 nữa để tận dụng tối đa dữ liệu\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    df['text_content'], df['tags_list'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. VECTOR HÓA (TF-IDF + SVD)\n",
    "# =============================================================================\n",
    "print(\"\\n--- 2. Tạo không gian Vector ngữ nghĩa ---\")\n",
    "# TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=10000, stop_words='english') \n",
    "X_train_tfidf = tfidf.fit_transform(X_train_text)\n",
    "X_test_tfidf = tfidf.transform(X_test_text)\n",
    "\n",
    "# SVD (Giảm chiều để tính khoảng cách chuẩn hơn)\n",
    "# SVD giúp vector 'xe hơi' và 'ô tô' xích lại gần nhau hơn\n",
    "svd = TruncatedSVD(n_components=200, random_state=42)\n",
    "X_train_vec = svd.fit_transform(X_train_tfidf)\n",
    "X_test_vec = svd.transform(X_test_tfidf)\n",
    "\n",
    "print(f\"Không gian vector: {X_train_vec.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. HỌC VỊ TRÍ CỦA CÁC TAG (TAG CENTROIDS)\n",
    "# =============================================================================\n",
    "print(\"\\n--- 3. Tính toán vị trí trung tâm (Centroids) của từng Tag ---\")\n",
    "tag_centroids = {}\n",
    "tag_counts = {}\n",
    "\n",
    "# Duyệt qua từng bài train để cộng dồn vector cho tag tương ứng\n",
    "# X_train_vec là numpy array, y_train là Series\n",
    "y_train_values = y_train.values\n",
    "\n",
    "for i in range(len(y_train_values)):\n",
    "    vec = X_train_vec[i]\n",
    "    tags = y_train_values[i]\n",
    "    for tag in tags:\n",
    "        if tag not in tag_centroids:\n",
    "            tag_centroids[tag] = np.zeros(200) # 200 là n_components của SVD\n",
    "            tag_counts[tag] = 0\n",
    "        tag_centroids[tag] += vec\n",
    "        tag_counts[tag] += 1\n",
    "\n",
    "# Chia trung bình để ra Centroid\n",
    "unique_tags = []\n",
    "centroid_vectors = []\n",
    "\n",
    "for tag in tag_centroids:\n",
    "    tag_centroids[tag] /= tag_counts[tag]\n",
    "    unique_tags.append(tag)\n",
    "    centroid_vectors.append(tag_centroids[tag])\n",
    "\n",
    "centroid_matrix = np.array(centroid_vectors)\n",
    "print(f\"Đã học được vị trí của {len(unique_tags)} tags.\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. PHÂN CỤM TAG (CLUSTERING) - ĐỂ LÀM SOFT METRIC\n",
    "# =============================================================================\n",
    "print(\"\\n--- 4. Phân cụm các Tags (Tạo nhóm ngữ nghĩa) ---\")\n",
    "# Số lượng cụm = 1/5 tổng số tag (hoặc tối đa 50)\n",
    "n_clusters = min(50, len(unique_tags) // 2)\n",
    "if n_clusters < 2: n_clusters = 2\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "tag_clusters = kmeans.fit_predict(centroid_matrix)\n",
    "\n",
    "# Map: Tag -> Cluster ID\n",
    "tag_to_cluster = {tag: cid for tag, cid in zip(unique_tags, tag_clusters)}\n",
    "\n",
    "# =============================================================================\n",
    "# 5. DỰ ĐOÁN & ĐÁNH GIÁ (Dựa trên khoảng cách)\n",
    "# =============================================================================\n",
    "print(\"\\n--- 5. Dự đoán trên tập Test ---\")\n",
    "\n",
    "# Tính độ tương đồng (Cosine Similarity) giữa Bài viết Test và Tất cả Tags\n",
    "# Kết quả là ma trận (Số bài test x Số lượng tags)\n",
    "similarity_matrix = cosine_similarity(X_test_vec, centroid_matrix)\n",
    "\n",
    "# Lấy Top 3 Tags gần nhất cho mỗi bài\n",
    "top_k = 3\n",
    "# argsort trả về index của tag, lấy từ thấp đến cao nên cần đảo ngược [::-1]\n",
    "top_k_indices = np.argsort(similarity_matrix, axis=1)[:, ::-1][:, :top_k]\n",
    "\n",
    "y_pred = []\n",
    "for idx_row in top_k_indices:\n",
    "    # Map từ index quay lại tên Tag\n",
    "    pred_tags = [unique_tags[idx] for idx in idx_row]\n",
    "    y_pred.append(pred_tags)\n",
    "\n",
    "# --- ĐÁNH GIÁ ---\n",
    "print(\"\\n--- KẾT QUẢ ĐÁNH GIÁ ---\")\n",
    "\n",
    "# Hàm tính độ chính xác dựa trên Cluster (Soft Metric)\n",
    "def evaluate_soft_cluster(y_true, y_pred, tag_to_cluster):\n",
    "    correct_count = 0\n",
    "    total = 0\n",
    "    \n",
    "    for true_tags, pred_tags in zip(y_true, y_pred):\n",
    "        if not pred_tags: continue\n",
    "        \n",
    "        # 1. Lấy tất cả Cluster ID của nhãn thật\n",
    "        true_cluster_ids = set()\n",
    "        for t in true_tags:\n",
    "            if t in tag_to_cluster:\n",
    "                true_cluster_ids.add(tag_to_cluster[t])\n",
    "        \n",
    "        # 2. Kiểm tra xem Tag dự đoán CAO NHẤT (Top 1) có thuộc cụm đúng không?\n",
    "        top_1_pred = pred_tags[0]\n",
    "        pred_cluster = tag_to_cluster.get(top_1_pred, -1)\n",
    "        \n",
    "        if pred_cluster in true_cluster_ids:\n",
    "            correct_count += 1\n",
    "        \n",
    "        total += 1\n",
    "        \n",
    "    return correct_count / total\n",
    "\n",
    "soft_acc = evaluate_soft_cluster(y_test.values, y_pred, tag_to_cluster)\n",
    "\n",
    "print(f\"Tổng số bài test: {len(y_test)}\")\n",
    "print(f\"Cluster-based Soft Accuracy: {soft_acc:.4f}\")\n",
    "print(\"(Nghĩa là: {:.2f}% số bài viết được gán nhãn ĐÚNG CHỦ ĐỀ/NHÓM NGỮ NGHĨA)\".format(soft_acc * 100))\n",
    "\n",
    "# In ví dụ minh họa\n",
    "print(\"\\n--- Ví dụ thực tế ---\")\n",
    "for i in range(5):\n",
    "    true_t = y_test.values[i]\n",
    "    pred_t = y_pred[i] # Top 3 dự đoán\n",
    "    \n",
    "    # Lấy Cluster ID để so sánh\n",
    "    true_c = [tag_to_cluster.get(t, 'N/A') for t in true_t]\n",
    "    pred_c_top1 = tag_to_cluster.get(pred_t[0], 'N/A')\n",
    "    \n",
    "    match_status = \"ĐÚNG CỤM\" if pred_c_top1 in true_c else \"SAI\"\n",
    "    \n",
    "    print(f\"Bài {i}:\")\n",
    "    print(f\"  - Tag thật: {true_t} (Cụm ID: {true_c})\")\n",
    "    print(f\"  - Dự đoán:  {pred_t} (Top 1 Cụm ID: {pred_c_top1})\")\n",
    "    print(f\"  => Kết quả: {match_status}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666d0da6-7481-40d1-b97e-3f2b6f0fad9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
